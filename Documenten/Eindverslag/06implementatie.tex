\section{Implementatie}
\label{Implementatie}
In de tweede week van het project zijn we echt begonnen met het bouwen van het systeem. We zijn begonnen met zogenaamde spike solutions (snelle simpele oplossingen om een deelprobleem op te lossen) van verschillende basis functionaliteiten, zoals het uploaden van images en het plaatsen van landmarks geplaatste images met behulp van drag \& drop. In een later stadium hebben we voor de grotere uitdagingen spike solutions geschreven, hieronder vallen bijvoorbeeld het morphen van plaatjes en het visualiseren van het Point Distribution Model. Als een spiked solutions werkte werd deze aan het bestaande systeem gekoppeld, op deze manier hadden we in een vrij korte tijd een basis systeem met haar basis functionaliteiten. Zo konden we ons vervolgens concentreren op de Javascript functies welke zouden gaan zorgen voor de AJAX afhandeling en de visuele effecten.

\subsection{Project gerelateerd}
Daar waar het mogelijk en handig was hebben we geprogrammeerd in tweetallen. Tijdens de implementatie fase hebben we veel gebruik gemaakt van de beschikbare whiteboards, deze waren handig voor het brainstormen en als iemand vast liep dan kon het probleem getekend en uitgelegd worden. Dit alles zorgde voor een goede synergie en hield iedereen de motivatie die hij had goed vast.
Ook tijdens de implementatie fase hebben we veel contact gehad met de leden van het \casamproject en zijn er verschillende tussentijdse presentaties geweest. Steeds hebben we na deze presentaties een uitgebreid overleg gehad over de stand van zaken en ge\"{e}valueerd over hoe het project er voor stond. In sommige gevallen hebben we ook onze prioriteitenlijst aangepast aan de hand van deze vergaderingen.

\subsection{Database systeem}
Lorem ipsum

Voorbeeld van de implementatie van de bitmap creator python-javascript-html-flash-javascript-python

Op het eind van het project hadden we veel bereikt. Maar ook is er werk blijven liggen. Voorbeelden hiervan zijn: de ViewMode voor artsen en de analyse van statische data.

\subsection{Image Processing}
Dit was een van de grootste uitdagingen van het project. Niemand had ervaring met de verschillende bibliotheken of uitgebreide ervaring met dit aspect van Image Processing. Er waren verschillende opties om de benodigde technieken te implementeren, zo konden we ze zelf implementeren met behulp van Numpy\cite{numpy}, of gebruik maken van grotere libraries zoals Insight Segmentation and Registration Toolkit (ITK)\cite{ITK} of de Visualization Toolkit (VTK)\cite{vtk}. Verder was er nog de Python Imaging Library (PIL)\cite{pil}, die geschikt is om eenvoudige beeldbewerking te doen. Uiteindelijk is er, mede op advies van Dr. Botha, gekozen voor PIL in combinatie met de VTK library. Om aan de vraagstelling te kunnen voldoen (het in kaart brengen van de variaties per landmark en het kunnen projecteren van getekende gebieden op één gemiddeld plaatje) hebben we gekozen om een deel van de methode Active Shape Modeling, genaamd Point Distribution Models, toe te passen in combinatie met Thin Plate Spline transformaties. Hierdoor is het mogelijk voor de onderzoeker om op een wiskundige verantwoorde manier anatomische structuren op een gemiddelde te projecteren en de variaties per landmark te visualiseren.
Al snel bleek dat er veel research nodig was om de theorie achter Principal Component Analysis, Active Shape Models, Point Distribution Models en de Thin Plate Spline Transformaties te doorgronden. Ook kostte het enige extra tijd om met de VTK bibliotheek zelf bekend te raken.

\subsubsection{Point Distribution Model}
Om het Point Distribution Model te maken is een set nodig van verschillende landmarks waarvan de variaties en de gemiddelden interessant zijn om weer te geven. Het is hierbij van belang om de landmarks zo te kiezen dat ze makkelijk zijn te vinden in elke foto en belangrijke punten aangeven op de structuur waar het om gaat. De gebruiker kan landmarks in de foto aangeven door eerst een landmarktype aan te maken, dan een landmark van een bepaald type en hierbij aan te geven of het een shapedefining landmark is of niet. Nadat de gebruiker in de foto's de gewenste landmarks heeft aangegeven kan hij door 'Analyse selected landmarks' aan te klikken het Point Distribution Model van de geselecteerde landmarks uitrekenen en weergeven.

Op dit moment wordt in JavaScript gecontroleerd welke images en landmarks geselecteerd zijn en wordt via een AJaX request de id's van de image en de geselecteerde landmarks per image doorgegeven. Aan de hand van de id's van de image en de landmarks worden vervolgens de bijbehorende objecten uit de database gehaald. In de view wordt getest of de geselecteerde landmarks wel geschikt zijn om een Point Distribution Model van te maken. Dit is bijvoorbeeld niet zo als er geen landmarks geselecteerd zijn, als er te weinig landmarks geselecteerd zijn van een type of als de geselecteerde landmarks van een geheel ander type zijn. In elk van deze gevallen wordt er een foutmelding aan de gebruiker geretourneerd in de vorm van een JavaScript alert met de aard van de fout, zodat de gebruiker zijn selectie kan aanpassen.

Als echter de juiste landmarks zijn geselecteerd worden allereerst via de co\"{o}rdinaten van de landmarks per image een vtkUnstructuredGrid aan gemaakt met de desbetreffende punten erin als vertices. Vervolgens wordt over deze grids de Generalized Procrustes Analysis uitgevoerd via het vtkProcrustesAlignmentFilter. Dit zorgt ervoor dat de gevonden modi van variatie onafhankelijk van de positie en de rotatie van de objecten zijn. Door ervoor te kiezen om de mode op RigidBody te zetten blijft echter wel de grootte van de structuren behouden. De opgeslagen grids zijn nu iteratief getransleerd en geroteerd naar elkaar toe.

Nu is het tijd om de Principal Component Analysis (PCA) op de aligned grids uit te voeren, dit is gedaan met behulp van het vtkPCAAnalysisFilter. Uit het resultaat kunnen de gemiddelde posities per landmark gehaald worden. We hebben er voor gekozen om de eerste twee modi van variatie te berekenen, de hoofdmodus van variatie (eerste mode) zorgt altijd voor de grootste verandering en is de eigenvector die uit de PCA komt met de grootste eigenwaarde. Om deze variaties te berekenen vragen we de GetParameterisedShape en berekenen we hiermee voor de eerste en tweede modus de extremen, dat wil zeggen plus en min 3 standaarddeviaties van het gemiddelde.

Nu we de benodigde co\"{o}rdinaten hebben (gemiddelde en extremen) kunnen we beginnen aan de visualisatie van de landmarks. Dit wordt gedaan met behulp van de PIL. Aan de hand van de afmetingen van de originele images en de gegeven co\"{o}rdinaten word voor het gemiddelde een ellipse getekend. Tussen de extremen van de twee hoofdmodi van variatie wordt een lijn getekend. De lengte van deze lijn geeft de grootte van de mogelijke variatie aan op basis van de voorbeelden uit de gegeven landmarks. Door de ellipsoids en lijnen weer te geven met een doorzichtige achtergrond is het vervolgens mogelijk om deze als een overlay over de images te projecteren. De overlay word opgeslagen in de database is beschikbaar voor weergave vanuit de interface.


\subsubsection{Thin Plate Spline Transformatie}
Toen het tijd was om de daadwerkelijke morph uit te voeren van de getekende structuren moesten we eerst een transformatie uitvoeren om verschillen in translaties en rotaties tussen de verschillende foto's te verwijderen. Na overleg met dr. Botha is besloten om dit niet via Generalized Procrustes Aligment te doen maar om \'{e}\'{e}n foto (in dit geval de eerste) als de voorbeeld te zien en alle andere getekende structuren naar deze foto te morphen. Dit heeft een groot voordeel, als er namelijk van een foto die naar het gemiddelde van de landmarks wordt gemorphed wordt er een anatomie verondersteld die niet echt is, het is dan bijvoorbeeld een niet bestaand been. Als er echter een bestaande foto wordt gebruikt om naar toe te morphen is het een bestaande anatomie. Helaas kwam de implementatie van dit onderdeel van het project te laat om ook nog het Point Distribution Model volgens deze gedachte te implementeren. 

In grote lijnen werkt de implementatie op dezelfde methode als die van het Point Distribution Model met een paar verschillen. Wederom worden landmarks uit de interface ingelezen en opgehaald. Er wordt naast de eerdergenoemde checks ook nog gekeken of de landmarks wel allemaal shapedefining zijn. Voor het morphproces worden namelijk een ander soort landmarks gebruikt van voor het berekenen van het Point Distribution Model. De shapedefining landmarks zijn landmarks die kenmerkend zijn voor de vorm van het hele object (je kunt hierbij denken aan bijvoorbeeld de bony landmarks van het been met daartussen op gelijke afstanden geplaatste landmarks op de omtrek van het been). 

Met de gevonden images en de bijbehorende landmarks worden de c\"{o}\"{o}rdinaten van de landmarks ditmaal direct in 


\subsubsection{Tekenen}
De Flash-applicatie die ontworpen is om de gebruiker de mogelijkheid te geven belangrijke gebieden te arceren werkt als volgt. Vanuit de applicatie kan op twee manieren de Flash-applicatie gestart worden. Het kan door in het rechter scherm met Possible Measuerments een nieuwe bitmap aan te maken terwijl een image actief is. De tweede methode is om een bestaande bitmap die aan een image gekoppeld is te bewerken door in het linker vak op de edit-knop te klikken.

Dit opent een FlashMovie waaraan in een HTML-tag argumenten meegegeven worden, zoals een verwijzing naar de achtergrondfoto en een optionele bestaande bitmap. In de Flash-applicatie kan vervolgens in een aparte laag getekend worden in één kleur. Als op de Save-knop gedrukt wordt scand de Flash-applicatie de hele tekenlaag per pixel af om een compacte representatie te maken van de tekening. Deze wordt vervolgens naar de server gestuurd met een HTTP-POST, samen met wat andere gegevens. Als de server dit succesvol afvangt en verwerkt krijgt de Flash-applicatie een response en roept de applicatie een JavaScript-functie in de browser aan die de Flash-applicatie afsluit.

Een probleem dat optrad bij grote foto's was dat het afscannen van de tekenlaag enkele seconden kon duren. Hierom is een extra optimalisatie ingebouwd: de applicatie houdt bij in welk gebied getekend is door een minimale en maximale x en y bij te houden. Op deze manier hoeft maar een beperkt deel van de laag gescand worden wat meestal significant veel tijd bespaard. In het ergste geval is over de hele image getekend en dan levert deze optimalisatie geen winst maar ook geen verlies op. Omdat de applicatie bij elke muisbeweging wel de minimale en maximale coördinaten bijwerkt kan het zijn dat hij iets inder gevoelig is voor de tekenbeweging zelf, maar dit bleek uit tests niet storend.

Als een al bestaande bitmap wordt geladen worden daarbij ook de vorige minimale en maximale coördinaten geladen. Binnen die bereik scand de Flash-applicatie de oude bitmap pixel voor pixel af voordat de eerste gekleurde pixel gevonden wordt om de vorige kleur te pakken te krijgen. 

\subsubsection{Tekenen: de serverkant}
De POST van de Flash applicatie is zo compact mogelijk opgebouwd. Deze bestaat uit een header met de afmetingen en de coördinaten van het tekengebied. De data zelf bestaat uit nummers die aangeven hoeveel pixels aaneengesloten gekleurd zijn of niet. Op deze manier zou dus een compleet geleurde bitmap maar bestaan uit \'e \'e n getal.

De server bouwt deze representatie om naar een grote string met één karakter per pixel, die met een methode uit de PIL opgeslagen kan worden als GIF-afbeelding. Er wordt ook een palet gekoppeld aan de GIF-afbeeldingen met als 255'ste waarde de kleur die in de Flash-applicatie gekozen is. Op deze manier wordt de bitmap (die in de Flash-applicatie nog uit meerdere kleuren kon bestaan) opgeslagen als een GIF-afbeelding met de laatst gebruikte kleur.

Het is nog niet mogelijk om een bitmap die al bestaat te berwerken om deze vervolgens compleet te wissen en een legen op te slaan. In dit geval wordt de lege bitmap niet opgeslagen.
